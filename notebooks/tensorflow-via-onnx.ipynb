{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b9c76a1",
   "metadata": {},
   "source": [
    "# TensorFlow: Deploy model to Vespa through ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b8f34d-4ece-4f3f-b01b-df7df32a279f",
   "metadata": {},
   "source": [
    "This tutorial will cover the following steps:\n",
    "\n",
    "1. Download labeled data containing Vespa ranking features.\n",
    "2. Create a listwise dataset based on a TensorFlow data pipeline.\n",
    "3. Train a Learning to Rank model (LTR) model using the TensorFlow Ranking framework.\n",
    "4. Simplify the LTR model to be suitable for ranking in Vespa\n",
    "5. Convert to TensorFlow model to ONNX file format.\n",
    "6. Create and deploy a Vespa application that uses the TensorFlow model\n",
    "7. Feed data to the Vespa application\n",
    "8. Ensure that prediction from the model deployed to Vespa match those obtained from the model directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af8b0d",
   "metadata": {},
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d00d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -Uqq pyvespa learntorank numpy pandas tensorflow tensorflow_ranking onnx tf2onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16ae8a4",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10c34b6b-fc26-4e6d-b28a-e20fd32c08c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df15e9c-31da-4e67-a9dd-0d2bf8f0478c",
   "metadata": {},
   "source": [
    "Download labeled data containing Vespa ranking features collected from an MS Marco passage ranking application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd0dede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://data.vespa.oath.cloud/blog/ranking/train_sample.csv\")\n",
    "df = df[\n",
    "    [\"document_id\", \n",
    "     \"query_id\", \n",
    "     \"label\", \n",
    "     \"fieldMatch(body).queryCompleteness\",\n",
    "     \"fieldMatch(body).significance\",\n",
    "     \"nativeRank\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "228e5b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7136b0-64e3-4f44-a665-c7a53713e7f9",
   "metadata": {},
   "source": [
    "For each `query_id`, there is 9 irrelevant `document_id` with `label = 0` and 1 relevant `document_id` with `label = 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7757b80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>query_id</th>\n",
       "      <th>label</th>\n",
       "      <th>fieldMatch(body).queryCompleteness</th>\n",
       "      <th>fieldMatch(body).significance</th>\n",
       "      <th>nativeRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27061</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.566311</td>\n",
       "      <td>0.042421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>257</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.582570</td>\n",
       "      <td>0.039192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>363</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.466030</td>\n",
       "      <td>0.034418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22682</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.566311</td>\n",
       "      <td>0.061149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.437808</td>\n",
       "      <td>0.035017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>228</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.437808</td>\n",
       "      <td>0.032697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3901893</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.748064</td>\n",
       "      <td>0.074917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1142680</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.748064</td>\n",
       "      <td>0.099112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>141</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.442879</td>\n",
       "      <td>0.038093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3060834</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.763933</td>\n",
       "      <td>0.075347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document_id  query_id  label  fieldMatch(body).queryCompleteness  \\\n",
       "0        27061         3      0                               0.625   \n",
       "1          257         3      0                               0.625   \n",
       "2          363         3      0                               0.500   \n",
       "3        22682         3      0                               0.625   \n",
       "4          160         3      0                               0.500   \n",
       "5          228         3      0                               0.500   \n",
       "6      3901893         3      0                               0.750   \n",
       "7      1142680         3      1                               0.750   \n",
       "8          141         3      0                               0.500   \n",
       "9      3060834         3      0                               0.750   \n",
       "\n",
       "   fieldMatch(body).significance  nativeRank  \n",
       "0                       0.566311    0.042421  \n",
       "1                       0.582570    0.039192  \n",
       "2                       0.466030    0.034418  \n",
       "3                       0.566311    0.061149  \n",
       "4                       0.437808    0.035017  \n",
       "5                       0.437808    0.032697  \n",
       "6                       0.748064    0.074917  \n",
       "7                       0.748064    0.099112  \n",
       "8                       0.442879    0.038093  \n",
       "9                       0.763933    0.075347  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90857ac",
   "metadata": {},
   "source": [
    "## Create a listwise dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df6ee38-dec1-44d9-af15-b819f2a6614c",
   "metadata": {},
   "source": [
    "Define some parameters required to setup the listwise data pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18b36a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_documents_per_query = 10            \n",
    "feature_names = [                         \n",
    "    \"fieldMatch(body).queryCompleteness\", \n",
    "    \"fieldMatch(body).significance\", \n",
    "    \"nativeRank\"\n",
    "]\n",
    "number_features = len(feature_names)\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92617ab4-59eb-46f7-85c8-17ea949230a3",
   "metadata": {},
   "source": [
    "Each feature data point will have the shape equal to `(batch_size, number_documents_per_query, number_features)` and each label data point will have shape equal to `(batch_size, number_documents_per_query)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fc4197-cfa6-44b9-8d4a-797ee1a45eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898d702f-78e4-4b38-820c-7efe64b8511f",
   "metadata": {},
   "source": [
    "The code below creates a TensorFlow data pipeline (`tf.data.Dataset`) from our DataFrame and group the rows by the `query_id` variable to form a listwise dataset. We then configure the data pipeline to shuffle and set a batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfa6061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_buffer_size = 10000\n",
    "ds = tf.data.Dataset.from_tensor_slices(\n",
    "    {\n",
    "        \"features\": tf.cast(df[feature_names].values, tf.float32),\n",
    "        \"label\": tf.cast(df[\"label\"].values, tf.float32),\n",
    "        \"query_id\": tf.cast(df[\"query_id\"].values, tf.int64),\n",
    "    }\n",
    ")\n",
    "\n",
    "key_func = lambda x: x[\"query_id\"]\n",
    "reduce_func = lambda key, dataset: dataset.batch(\n",
    "    number_documents_per_query, drop_remainder=True\n",
    ")\n",
    "listwise_ds = ds.group_by_window(\n",
    "    key_func=key_func,\n",
    "    reduce_func=reduce_func,\n",
    "    window_size=number_documents_per_query,\n",
    ")\n",
    "listwise_ds = listwise_ds.map(lambda x: (x[\"features\"], x[\"label\"]))\n",
    "listwise_ds = listwise_ds.shuffle(buffer_size=shuffle_buffer_size).batch(\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f465be76-0794-4269-9567-b5dd99b21221",
   "metadata": {},
   "source": [
    "We can see the shape of the `features` and of the `labels` are as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "273144fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 10, 3)\n",
      "(32, 10)\n"
     ]
    }
   ],
   "source": [
    "for d in listwise_ds.take(1):\n",
    "    print(d[0].shape)\n",
    "    print(d[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a96ae0e",
   "metadata": {},
   "source": [
    "## Create and compile model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d79f9cb-4971-4a09-a2d3-c6b2eaacb7a6",
   "metadata": {},
   "source": [
    "We are going to create a linear model that can take a listwise data as input with shape `(batch_size, number_documents_per_query, number_features)` and output one prediction per document with shape `(batch_size, number_documents_per_query)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3870f9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.keras.layers.Input(shape=(number_documents_per_query, number_features))\n",
    "dense_layer = tf.keras.layers.Dense(\n",
    "    1,\n",
    "    use_bias=False,\n",
    "    activation=None,\n",
    "    name=\"dense\"\n",
    ")\n",
    "output_layer = tf.keras.layers.Reshape((number_documents_per_query,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c247e8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(layers=[input_layer, dense_layer, output_layer])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92a6ecc-0579-4ff3-8430-f96f33e417e7",
   "metadata": {},
   "source": [
    "In this tutorial, we want to optimize the [Normalized Discounted Cumulative Gain](https://en.wikipedia.org/wiki/Discounted_cumulative_gain#Normalized_DCG) at position 10 (NDCG@10). We then select a loss function that is a smooth approximation of the NDCG metric and create a stateless NDCG@10 metric to use when compiling the model defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1df7a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_ranking as tfr\n",
    "\n",
    "ndcg = tfr.keras.metrics.NDCGMetric(topn=10)\n",
    "def ndcg_stateless(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Create stateless metric so that we can compute the validation metric \n",
    "    from scratch at the end of each epoch.\n",
    "    \"\"\"\n",
    "    ndcg.reset_states()\n",
    "    return ndcg(y_true, y_pred)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adagrad(learning_rate=2)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tfr.keras.losses.ApproxNDCGLoss(),\n",
    "    metrics=ndcg_stateless,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef81f6a-2276-49f8-ab3d-fd588076085b",
   "metadata": {},
   "source": [
    "Use the listwise dataset to fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fbce1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "304/304 [==============================] - 8s 3ms/step - loss: -0.6522 - ndcg_stateless: 0.6874\n",
      "Epoch 2/20\n",
      "304/304 [==============================] - 1s 921us/step - loss: -0.6959 - ndcg_stateless: 0.7159\n",
      "Epoch 3/20\n",
      "304/304 [==============================] - 1s 905us/step - loss: -0.7001 - ndcg_stateless: 0.7166\n",
      "Epoch 4/20\n",
      "304/304 [==============================] - 1s 904us/step - loss: -0.7025 - ndcg_stateless: 0.7168\n",
      "Epoch 5/20\n",
      "304/304 [==============================] - 1s 901us/step - loss: -0.7043 - ndcg_stateless: 0.7165\n",
      "Epoch 6/20\n",
      "304/304 [==============================] - 1s 920us/step - loss: -0.7106 - ndcg_stateless: 0.7242\n",
      "Epoch 7/20\n",
      "304/304 [==============================] - 1s 903us/step - loss: -0.7355 - ndcg_stateless: 0.7647\n",
      "Epoch 8/20\n",
      "304/304 [==============================] - 1s 898us/step - loss: -0.7399 - ndcg_stateless: 0.7662\n",
      "Epoch 9/20\n",
      "304/304 [==============================] - 1s 923us/step - loss: -0.7430 - ndcg_stateless: 0.7679\n",
      "Epoch 10/20\n",
      "304/304 [==============================] - 1s 911us/step - loss: -0.7450 - ndcg_stateless: 0.7679\n",
      "Epoch 11/20\n",
      "304/304 [==============================] - 1s 955us/step - loss: -0.7464 - ndcg_stateless: 0.7682\n",
      "Epoch 12/20\n",
      "304/304 [==============================] - 1s 914us/step - loss: -0.7475 - ndcg_stateless: 0.7683\n",
      "Epoch 13/20\n",
      "304/304 [==============================] - 1s 919us/step - loss: -0.7485 - ndcg_stateless: 0.7689\n",
      "Epoch 14/20\n",
      "304/304 [==============================] - 1s 909us/step - loss: -0.7493 - ndcg_stateless: 0.7682\n",
      "Epoch 15/20\n",
      "304/304 [==============================] - 1s 904us/step - loss: -0.7499 - ndcg_stateless: 0.7692\n",
      "Epoch 16/20\n",
      "304/304 [==============================] - 1s 900us/step - loss: -0.7506 - ndcg_stateless: 0.7691\n",
      "Epoch 17/20\n",
      "304/304 [==============================] - 1s 893us/step - loss: -0.7513 - ndcg_stateless: 0.7699\n",
      "Epoch 18/20\n",
      "304/304 [==============================] - 1s 1ms/step - loss: -0.7516 - ndcg_stateless: 0.7694\n",
      "Epoch 19/20\n",
      "304/304 [==============================] - 1s 910us/step - loss: -0.7520 - ndcg_stateless: 0.7694\n",
      "Epoch 20/20\n",
      "304/304 [==============================] - 1s 830us/step - loss: -0.7524 - ndcg_stateless: 0.7686\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(listwise_ds, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8624f1",
   "metadata": {},
   "source": [
    "## Simplify model input/output for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11289353-1363-47da-a57a-2c8c93d90732",
   "metadata": {},
   "source": [
    "After training the model by minimizing a listwise loss function, we can simplify the model before deploying it to Vespa. At inference time, Vespa will evaluate each document individually and use a ranking function to rank documents.\n",
    "\n",
    "Therefore, the input layer will expect a tensor named `input` with shape equal to `(1, number_features)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63458df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpler_model = tf.keras.Sequential(\n",
    "    [tf.keras.layers.Input(shape=(number_features,), batch_size=1, name=\"input\"), \n",
    "     dense_layer\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211dd9d1-6a54-435a-b129-35cf465bf483",
   "metadata": {},
   "source": [
    "We are going to save the `simpler_model` to disk and then use the tf2onnx tool to convert the model to ONNX format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07e3084d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: simpler_keras_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: simpler_keras_model/assets\n"
     ]
    }
   ],
   "source": [
    "simpler_model.save(\"simpler_keras_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ac7602c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<frozen runpy>:128: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "2023-08-08 14:09:40,224 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "2023-08-08 14:09:40,328 - INFO - Signatures found in model: [serving_default].\n",
      "2023-08-08 14:09:40,328 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
      "2023-08-08 14:09:40,328 - INFO - Output names: ['dense']\n",
      "2023-08-08 14:09:40,328 - WARNING - Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.11/site-packages/tf2onnx/tf_loader.py:557: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "2023-08-08 14:09:40,379 - WARNING - From /usr/local/lib/python3.11/site-packages/tf2onnx/tf_loader.py:557: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "2023-08-08 14:09:40,388 - INFO - Using tensorflow=2.13.0, onnx=1.14.0, tf2onnx=1.8.4/cd55bf\n",
      "2023-08-08 14:09:40,388 - INFO - Using opset <onnx, 9>\n",
      "2023-08-08 14:09:40,389 - INFO - Computed 0 values for constant folding\n",
      "2023-08-08 14:09:40,395 - INFO - Optimizing ONNX model\n",
      "2023-08-08 14:09:40,402 - INFO - After optimization: Identity -5 (5->0)\n",
      "2023-08-08 14:09:40,403 - INFO - \n",
      "2023-08-08 14:09:40,403 - INFO - Successfully converted TensorFlow model simpler_keras_model to ONNX\n",
      "2023-08-08 14:09:40,403 - INFO - Model inputs: ['input:0']\n",
      "2023-08-08 14:09:40,403 - INFO - Model outputs: ['dense']\n",
      "2023-08-08 14:09:40,403 - INFO - ONNX model is saved at simpler_keras_model.onnx\n"
     ]
    }
   ],
   "source": [
    "from tf2onnx import convert\n",
    "\n",
    "!python3 -m tf2onnx.convert --saved-model simpler_keras_model --output simpler_keras_model.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e41cd5-23bb-4fe2-863b-1e5d29b7d45f",
   "metadata": {},
   "source": [
    "We can inspect the onnx model input and output. We first load the ONNX model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c61ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx                  \n",
    "\n",
    "m = onnx.load(\"simpler_keras_model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82fd69f-64d2-4503-8b63-1490ff846987",
   "metadata": {},
   "source": [
    "As mentioned before, the model expects a tensor named `input` with shape `(1, 3)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b903c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"input:0\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: 1\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 1\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 3\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.graph.input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7ce858-5b83-4a18-82cf-91b6a45cbb2d",
   "metadata": {},
   "source": [
    "The output will be a tensor named `dense` with shape `(1,1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e3e0cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"dense\"\n",
       "type {\n",
       "  tensor_type {\n",
       "    elem_type: 1\n",
       "    shape {\n",
       "      dim {\n",
       "        dim_value: 1\n",
       "      }\n",
       "      dim {\n",
       "        dim_value: 1\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.graph.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf25667",
   "metadata": {},
   "source": [
    "## Define the application package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a38f0be-7f8c-41c0-8bcd-b29e708ea6e2",
   "metadata": {},
   "source": [
    "This section will use the Vespa python API `pyvespa` to create an application package with a ranking function that uses the tensorflow model exported to ONNX. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9584db-bdb4-408b-b4fd-99365c49d60f",
   "metadata": {},
   "source": [
    "The data used to train the model was derived from a Vespa application based on the MS Marco passage dataset. So, we are going to name the application `msmarco`, and start by adding two fields: `id` to hold the document id and `text` to hold the passages from the msmarco dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429a8185-4207-4b92-87dc-262d8fa11f14",
   "metadata": {},
   "source": [
    "`indexing` configuration: We add `\"summary\"` to the `indexing` parameter because we want to include both the `id` and the `text` field in the query results. The `\"attribute\"` indicates that the field `id` will be stored in-memory. The `\"index\"` indicates that Vespa will create a search index for the `text` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8216ee71-3f90-437c-8162-aed12175a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.package import ApplicationPackage, Field\n",
    "\n",
    "app_package = ApplicationPackage(name=\"msmarco\")\n",
    "\n",
    "app_package.schema.add_fields(\n",
    "    Field(name=\"id\", type=\"string\", indexing=[\"summary\", \"attribute\"]),\n",
    "    Field(name=\"text\", type=\"string\", indexing=[\"summary\", \"index\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594b155c-ccc5-4d55-bed6-726883c106bf",
   "metadata": {},
   "source": [
    "Note that at each step along the application package definition, we can inspect the content of the Vespa search definition file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3390ae4-f915-4175-9483-2afc0f3433d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema msmarco {\n",
      "    document msmarco {\n",
      "        field id type string {\n",
      "            indexing: summary | attribute\n",
      "        }\n",
      "        field text type string {\n",
      "            indexing: summary | index\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(app_package.schema.schema_to_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901179db-54e7-4bac-b734-b294072da120",
   "metadata": {},
   "source": [
    "Add `simpler_keras_model.onnx` to the schema. \n",
    "* The `model_name` is an id that can be used in the ranking function to identify which model to use. \n",
    "* The `model_file_path` is the current path of the .onnx file. When deploying the application, `pyvespa` will move the file to the correct location inside the Vespa application package folder.\n",
    "* The `inputs` maps the name of the inputs contained in the ONNX model to the name of the Vespa source that will be used as input to the model. In this case we will create a function called `vespa_input` that output a tensor of type float with the expected shape `(1, 3)`.\n",
    "* The `outputs` maps the output name in the ONNX file to the output name that will be recognized by Vespa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26d8c14a-5f3a-4ab7-a7f3-77c0ec7fa2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.package import OnnxModel\n",
    "\n",
    "app_package.schema.add_model(\n",
    "    OnnxModel(\n",
    "        model_name=\"ltr_tensorflow\",\n",
    "        model_file_path=\"simpler_keras_model.onnx\",\n",
    "        inputs={\"input:0\": \"vespa_input\"},\n",
    "        outputs={\"dense\": \"dense\"},\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c77a85-b85b-4e6e-bbee-c50a115b55a5",
   "metadata": {},
   "source": [
    "It is possible to see the addition of the `onnx-model` section in the search definition below. Note that the model file is expected to be under the `files` folder inside the final application package folder, but `pyvespa` takes care of the model file placement when deploying the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fa5a806-5976-4085-967a-35534e02421b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema msmarco {\n",
      "    document msmarco {\n",
      "        field id type string {\n",
      "            indexing: summary | attribute\n",
      "        }\n",
      "        field text type string {\n",
      "            indexing: summary | index\n",
      "        }\n",
      "    }\n",
      "    onnx-model ltr_tensorflow {\n",
      "        file: files/ltr_tensorflow.onnx\n",
      "        input input:0: vespa_input\n",
      "        output dense: dense\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(app_package.schema.schema_to_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936807d9-3103-40cf-a82e-b1ccd26d8081",
   "metadata": {},
   "source": [
    "Add a rank profile named `tensorflow` that uses the TensorFlow model to rank documents. \n",
    "* `first_phase`: We use the Vespa ranking feature `onnx` to access the ONNX model named `ltr_tensorflow` and use the output `dense`. We apply the `sum` because Vespa requires the relevance score to be a scaler and the output of the ONNX model in this case is a tensor of shape `(1,1)`.\n",
    "* `vespa_input` function: The ONNX model was trained with the features `fieldMatch(text).queryCompleteness`, `fieldMatch(text).significance` and `nativeRank(text)` and expects and tensor of shape `(1,3)` containing those features.\n",
    "* `summary_features`: Summary features allow us to specify Vespa features to be included in the output of a query. In this case, we want to access to the model inputs and output to check if the Vespa model evaluation is the same as if we use the original TensorFlow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cc8dc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.package import RankProfile, Function\n",
    "\n",
    "app_package.schema.add_rank_profile(\n",
    "    RankProfile(\n",
    "        name=\"tensorflow\", \n",
    "        first_phase=\"sum(onnx(ltr_tensorflow).dense)\", \n",
    "        functions=[\n",
    "            Function(\n",
    "                name=\"vespa_input\", \n",
    "                expression=\"tensor<float>(x[1],y[3]):[[\"\n",
    "                    \"fieldMatch(text).queryCompleteness, \"\n",
    "                    \"fieldMatch(text).significance, \"\n",
    "                    \"nativeRank(text)\"\n",
    "                \"]]\"\n",
    "            )\n",
    "        ],\n",
    "        summary_features=[\n",
    "            \"onnx(ltr_tensorflow)\", \n",
    "            \"fieldMatch(text).queryCompleteness\", \n",
    "            \"fieldMatch(text).significance\", \n",
    "            \"nativeRank(text)\"\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd65efef-8e79-44b9-9d2c-bca8f4e3faf6",
   "metadata": {},
   "source": [
    "The `rank-profile` called tensorflow can be seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a750f2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema msmarco {\n",
      "    document msmarco {\n",
      "        field id type string {\n",
      "            indexing: summary | attribute\n",
      "        }\n",
      "        field text type string {\n",
      "            indexing: summary | index\n",
      "        }\n",
      "    }\n",
      "    onnx-model ltr_tensorflow {\n",
      "        file: files/ltr_tensorflow.onnx\n",
      "        input input:0: vespa_input\n",
      "        output dense: dense\n",
      "    }\n",
      "    rank-profile tensorflow {\n",
      "        function vespa_input() {\n",
      "            expression {\n",
      "                tensor<float>(x[1],y[3]):[[fieldMatch(text).queryCompleteness, fieldMatch(text).significance, nativeRank(text)]]\n",
      "            }\n",
      "        }\n",
      "        first-phase {\n",
      "            expression {\n",
      "                sum(onnx(ltr_tensorflow).dense)\n",
      "            }\n",
      "        }\n",
      "        summary-features {\n",
      "            onnx(ltr_tensorflow)\n",
      "            fieldMatch(text).queryCompleteness\n",
      "            fieldMatch(text).significance\n",
      "            nativeRank(text)\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(app_package.schema.schema_to_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c6d94c-870b-4824-a6cb-7ef5ef85bd05",
   "metadata": {},
   "source": [
    "Now that we are done with the application package definition. We can deploy the application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91408c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for configuration server, 0/300 seconds...\n",
      "Waiting for configuration server, 5/300 seconds...\n",
      "Waiting for application status, 0/300 seconds...\n",
      "Waiting for application status, 5/300 seconds...\n",
      "Waiting for application status, 10/300 seconds...\n",
      "Waiting for application status, 15/300 seconds...\n",
      "Waiting for application status, 20/300 seconds...\n",
      "Waiting for application status, 25/300 seconds...\n",
      "Finished deployment.\n"
     ]
    }
   ],
   "source": [
    "from vespa.deployment import VespaDocker\n",
    "\n",
    "vespa_docker = VespaDocker()\n",
    "app = vespa_docker.deploy(application_package=app_package)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78607f9a",
   "metadata": {},
   "source": [
    "## Feed the application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172242da-a942-4ff4-8095-c7f16a2f9ee7",
   "metadata": {},
   "source": [
    "Once the application is running, it is time to feed msmarco passage data to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa1b3f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from learntorank.passage import PassageData\n",
    "\n",
    "dataset = PassageData.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65ae672-f618-41a2-b6a8-39ff3ba24762",
   "metadata": {},
   "source": [
    "We are going to use only 10 documents because our goal here is to show that Vespa returns the correct predictions from the TensorFlow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9a79d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.get_corpus().head(10)\n",
    "data.rename(columns={'doc_id': 'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c9d972a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5954248</td>\n",
       "      <td>Why GameStop is excited for Dragon Age: Inquis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7290700</td>\n",
       "      <td>metaplasia definition: 1. abnormal change of o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5465518</td>\n",
       "      <td>Candice Net Worth. According to the report of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3100518</td>\n",
       "      <td>Under the Base Closure Act, March AFB was down...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3207764</td>\n",
       "      <td>There are a number of career opportunities for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0  5954248  Why GameStop is excited for Dragon Age: Inquis...\n",
       "1  7290700  metaplasia definition: 1. abnormal change of o...\n",
       "2  5465518  Candice Net Worth. According to the report of ...\n",
       "3  3100518  Under the Base Closure Act, March AFB was down...\n",
       "4  3207764  There are a number of career opportunities for..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4be6af3-8cfe-440f-ac90-51f3b0cce802",
   "metadata": {},
   "source": [
    "Feed the `data` to the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0521de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful documents fed: 10/10.\n",
      "Batch progress: 1/1.\n"
     ]
    }
   ],
   "source": [
    "result = app.feed_df(df=data, include_id=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7df3f0",
   "metadata": {},
   "source": [
    "## Validate Vespa predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2a90f9-1ea9-4737-93df-bf667c2f5f23",
   "metadata": {},
   "source": [
    "Get query from the small dev set to use to validate Vespa TensorFlow predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d903bef4-7d60-48ab-9341-bcab1cd21e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = dataset.get_queries(type=\"dev\").iloc[0,1]\n",
    "query_text = query_text.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "433696e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'why say the sky is the limit'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ec295b-07cf-4047-92ea-57547c8d4094",
   "metadata": {},
   "source": [
    "The code below shows the YQL expression that will be used to select the documents to be ranked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ee901a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"select * from sources * where ({grammar: 'any', defaultIndex: 'text'}userInput('why say the sky is the limit'))\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"select * from sources * where ({{grammar: 'any', defaultIndex: 'text'}}userInput('{}'))\".format(query_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6943a3-93e2-476b-8b69-70ce30cff93b",
   "metadata": {},
   "source": [
    "The function `get_vespa_prediction_and_features` will match documents using the YQL expression above and rank the documents with the rank-profile `tensorflow` that we defined in the Vespa application package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "198733ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vespa_prediction_and_features(query_text):\n",
    "    # Send query and extract hits\n",
    "    hits = app.query(\n",
    "                body={\n",
    "                    \"yql\": \"select * from sources * where ({{'grammar': 'any', 'defaultIndex': 'text'}}userInput('{}'));\".format(query_text),\n",
    "                    \"ranking\": \"tensorflow\"\n",
    "                }\n",
    "            ).hits\n",
    "    result =[]\n",
    "    # For each hit, extract the inputs to the model along with model predictions computed by Vespa\n",
    "    for hit in hits:\n",
    "        result.append({\n",
    "            \"fieldMatch(text).queryCompleteness\": hit[\"fields\"][\"summaryfeatures\"][\"fieldMatch(text).queryCompleteness\"],\n",
    "            \"fieldMatch(text).significance\": hit[\"fields\"][\"summaryfeatures\"][\"fieldMatch(text).significance\"],\n",
    "            \"nativeRank(text)\": hit[\"fields\"][\"summaryfeatures\"][\"nativeRank(text)\"],\n",
    "            \"vespa_prediction\": hit[\"relevance\"],             \n",
    "        })\n",
    "    return pd.DataFrame.from_records(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f4db93-4b50-4536-9d2c-df4c3733b4d8",
   "metadata": {},
   "source": [
    "Inputs and vespa predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73763ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fieldMatch(text).queryCompleteness</th>\n",
       "      <th>fieldMatch(text).significance</th>\n",
       "      <th>nativeRank(text)</th>\n",
       "      <th>vespa_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.199799</td>\n",
       "      <td>0.061853</td>\n",
       "      <td>0.360788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.415687</td>\n",
       "      <td>0.086940</td>\n",
       "      <td>-0.128510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.302071</td>\n",
       "      <td>0.065154</td>\n",
       "      <td>-0.240481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.302071</td>\n",
       "      <td>0.050600</td>\n",
       "      <td>-0.670632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.302071</td>\n",
       "      <td>0.049802</td>\n",
       "      <td>-0.694231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.199799</td>\n",
       "      <td>0.025552</td>\n",
       "      <td>-0.712175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.302071</td>\n",
       "      <td>0.045398</td>\n",
       "      <td>-0.824390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fieldMatch(text).queryCompleteness  fieldMatch(text).significance  \\\n",
       "0                            0.285714                       0.199799   \n",
       "1                            0.571429                       0.415687   \n",
       "2                            0.428571                       0.302071   \n",
       "3                            0.428571                       0.302071   \n",
       "4                            0.428571                       0.302071   \n",
       "5                            0.285714                       0.199799   \n",
       "6                            0.428571                       0.302071   \n",
       "\n",
       "   nativeRank(text)  vespa_prediction  \n",
       "0          0.061853          0.360788  \n",
       "1          0.086940         -0.128510  \n",
       "2          0.065154         -0.240481  \n",
       "3          0.050600         -0.670632  \n",
       "4          0.049802         -0.694231  \n",
       "5          0.025552         -0.712175  \n",
       "6          0.045398         -0.824390  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = get_vespa_prediction_and_features(query_text=query_text)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a4cbf6-af0e-4329-aaff-819d677424fc",
   "metadata": {},
   "source": [
    "Compute predictions from the TensorFlow model `simpler_model` directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09e6a7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions[\"tf_prediction\"] = predictions[\n",
    "    [\"fieldMatch(text).queryCompleteness\", \"fieldMatch(text).significance\", \"nativeRank(text)\"]\n",
    "].apply(lambda x: simpler_model.predict([x.tolist()])[0][0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "241a332c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fieldMatch(text).queryCompleteness</th>\n",
       "      <th>fieldMatch(text).significance</th>\n",
       "      <th>nativeRank(text)</th>\n",
       "      <th>vespa_prediction</th>\n",
       "      <th>tf_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.199799</td>\n",
       "      <td>0.061853</td>\n",
       "      <td>0.360788</td>\n",
       "      <td>0.360788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.415687</td>\n",
       "      <td>0.086940</td>\n",
       "      <td>-0.128510</td>\n",
       "      <td>-0.128510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.302071</td>\n",
       "      <td>0.065154</td>\n",
       "      <td>-0.240481</td>\n",
       "      <td>-0.240481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.302071</td>\n",
       "      <td>0.050600</td>\n",
       "      <td>-0.670632</td>\n",
       "      <td>-0.670632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.302071</td>\n",
       "      <td>0.049802</td>\n",
       "      <td>-0.694231</td>\n",
       "      <td>-0.694231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.199799</td>\n",
       "      <td>0.025552</td>\n",
       "      <td>-0.712175</td>\n",
       "      <td>-0.712176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.302071</td>\n",
       "      <td>0.045398</td>\n",
       "      <td>-0.824390</td>\n",
       "      <td>-0.824390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fieldMatch(text).queryCompleteness  fieldMatch(text).significance  \\\n",
       "0                            0.285714                       0.199799   \n",
       "1                            0.571429                       0.415687   \n",
       "2                            0.428571                       0.302071   \n",
       "3                            0.428571                       0.302071   \n",
       "4                            0.428571                       0.302071   \n",
       "5                            0.285714                       0.199799   \n",
       "6                            0.428571                       0.302071   \n",
       "\n",
       "   nativeRank(text)  vespa_prediction  tf_prediction  \n",
       "0          0.061853          0.360788       0.360788  \n",
       "1          0.086940         -0.128510      -0.128510  \n",
       "2          0.065154         -0.240481      -0.240481  \n",
       "3          0.050600         -0.670632      -0.670632  \n",
       "4          0.049802         -0.694231      -0.694231  \n",
       "5          0.025552         -0.712175      -0.712176  \n",
       "6          0.045398         -0.824390      -0.824390  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53bbed0-2f59-4b0a-8a7a-fb28fde5b144",
   "metadata": {},
   "source": [
    "Check that the predictions from the model deployed in Vespa are (almost) equal to the predictions obtained directly from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e8802d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.testing import assert_almost_equal\n",
    "\n",
    "assert_almost_equal(predictions[\"vespa_prediction\"].tolist(), predictions[\"tf_prediction\"].tolist(), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3398800",
   "metadata": {},
   "source": [
    "## Clean environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8ff88cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"simpler_keras_model\") \n",
    "vespa_docker.container.stop(timeout=600)\n",
    "vespa_docker.container.remove()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
